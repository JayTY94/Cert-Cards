ogTeQOck6Z%dhD4H

2ba0cc4f-8c70-4898-b98e-a188fb342a7f

Extend the Value of File Data in Architecture, Engineering, and Construction Workflows with Nasuni

The architecture, engineering, and construction (AEC) industry is experiencing unprecedented growth in unstructured data. As a result, IT teams have been pushed to consider innovative strategies for file data storage and analytics.

Modern computer-aided design (CAD) and building information modeling (BIM) workflows have contributed to the need for collaboration between building architects and engineers.

In construction, new methods of capturing site information, such as laser scanning, photogrammetry, drone photography, and continuous video monitoring have presented challenges for file storage, analysis, and archiving.

Nasuni is an AWS Storage Competency Partner and file services platform on AWS that provides infinite file storage, backups, disaster recovery, and multi-site file sharing.

...

Automate and improve your security posture using AWS Backup and AWS PrivateLink

Enterprises set up their AWS environment preconfigured in-line with organizational security policies, compliance, and detective and preventive controls codeified right from the beginning. Furthermore, enterprises want to access cloud-native services in a manner simlar to how they have been consuming services in the past, from within their own ssecured networking environment according to their security policies. When consuming cloud-native services via their public endpoint, the request/response traffic (although in encrypted) is still exposed to the public internet. This may not be acceptable to security-conscious enterprises.

In this blog, I demonstrate how enterprises can uplift their security posture when using AWS Backup, helping them comply with thier regulatory requirements. AWS Backup now supports AWS PrivateLink, allowing enterprises to access AWS Backup from their VPC by using a VPC endpoint place within their private network space. In short, it eliminates the need to use the public internet for service access. In addition, extra controlscan be added via security group and VPC endpoint policy when accessing the service through the VPC endpoint.

Background

Orchestration and operations on the various AWS services, using methods such as AWS CLI and/or service API/SDK, are done via the underlying service's endpoint. A service's endpoint is the URL that provides the entry point to that service. These service endpoints are public and accessible over the internet (HTTPS). For example, the Sydney Region's endpoint for the AWS Backup service is backup.ap-southeast-2-amazonaws.com.

...

https://docs.aws.amazon.com/whitepapers/latest/using-power-bi-with-aws-cloud/using-power-bi-with-aws-cloud.pdf#introduction

...

Recommended configuration

AWS recommends that you install the Microsoft on-premises data gateway on an Amazon EC2 instance in the private subnet that contains your data sources. This subnet is configured to route requests to the internet via an Amazon VPC NAT gateway installed in a public subnet. You can use a network address translation (NAT) gateway to enable instances in a private subnet to connect to the internet or to other AWS services, but prevent the internet form connecting to those instances. If you require a highly available digital gateway implementation, we recommend using a cluster of on-premise data gateways installed accross multiple EC2 instances that span different AWS Availability Zones. For information, see Add another data gateway to a create a cluster.

The options presented in this section illustrate Amazon RDS, Amazon Redshift, and Amazon Athena. For a full discussion of all AWS data sources, refer to Appendix: Microsoft Power BI supported AWS data sources.

Additional Considerations

Network connectivity

    Microsoft on-premises data gateway connectivity to data sources is straight forward because both the data consumer and the data sources reside within the AWS Cloud. Data sources that live in an Amazon VPC, such as Amazon RDS and Amazon Redshift, can be accessed directly. Data sources that use regional endpoints can be accessed through the Amazon VPC internet gateway, or by an Amazon VPC endpoint.

    Microsoft on-premises data gateway connectivity to the Microsoft Power BI service occurs over the internet and is an outbound connection only. You can use a combination of routing and security groups to control access to data sources stored within the AWS Cloud.

    Because Microsoft on-premises data gateway is installed on an Amazon EC2 instance, it will have an associated security group that can be used to limit inbound accesss to the operating system. The gateway does not accept inbound requests. The instance does not need a public IP address, and should not be configured with one.

    Encryption in transit

    We recommend that data sources within an Amazon VPC are configured to use encryption for transmission of data. Regional services already make use of TLS encryption.

    Microsoft on-premises data gateway connectivity can be configured to connect to the Microsoft Azure Service Bus using HTTPS instead of TCP. We recommend using HTTPS mode for communication. This is also the default for new gateway installations since the June 2019 gateway software version release.

    Authentication

    AWS recommends that you authenticate with AWS data sources using an identity that has read-only access only to the datasets required. The credentials that you enter for a data source are encrypted and stored in the gateway cloud service. The credentials are decrypted at the gateway on premises. (The credentials that you enter for a data source are encrypted and stored in the gateway cloud service).

    Make sure that Microsoft Power BI credentials are securely controlled. Access to the services permits access to AWS data sources and potentially sensitive information they might contain.

Performance

    Microsoft on-premises data gateway in the AWS cloud typically performs well due to the ability to size and scale up the Amazon EC2 instance. It also performs fast in Region networking and connectivity to the internet.

Cost

    Three factors need to be considered: Amazon EC2 instance charges, transfer charges, and Amazon NAT gateway charges.

    Size your Amazon EC2 instances according to Microsoft's requirements. To reduce costs, you can pruchase Amazon EC2 reserved instances or AWS Savings Plans.

    Data transferred from the Microsoft on-premises data gateway to teh Microsoft Power BI service incurs VPC egress charges. Customers report a 10:1 compression by using the data gateway which will reduce the amount of traffic, but we recommend that you limit queries and use filters to ensure that only relevant data is transferred.

    If the Microsoft on-premises data gateway connects to data sources in different Availability Zones or different AWS Regions, data transfer charges also apply.

    If the Microsoft on-premises data gateways are located in private subnets and make user of an AWS NAT gateway, hourly and data processing charges apply. For more information, see Amazon VPC pricing.

Using Amazon QuickSight

Customers considering using the Microsoft Power BI Suite with AWS are encouraged to evaluate Amazon QuickSight as an alternative. This fully managed cloud service natively connects to data sources in AWS, reducing the complexity and cost when compared to other BI solutions.

How Amazon QuickSight works

When compared with other BI solutions, Amazon QuickSight has the following benefits:

    With Amazon QuickSight, there is no need to download and install a client application. All functionality, including authoring and reporting, can be accessed from any platform (Windows, Mac, Linux, and so forth) by a web browser.

    Amazon QuickSight is delivered as a fully managed, cloud-native SaaS application that is simple to build and deploy dashboards to production. The service is serverless, which means you do not need to calculate how many nodes and servers you need to support your users. QuickSight also takes full advantage of high availabilty features provided by AWS for resliliency.

    It's easy to get started in small or large settings, with the ability to add users from a point-and-click interface within QuickSight. No external administrator intervention is needed.

    Amazon QuickSight is powered by Super-fast, Parallel, in-memory Calculation Engine (SPICE) for a fast response time (in the milliseconds) and interactive visualizations. Datasets can currently scale up to 200 GB.

    Amazon QuickSight pricing is simple, inexpensive, and has two components: report authors and report readers. Report authors, who create and publish interactive dashboards, are priced per user. If users do not log in during a given month, there are no charges for those users. Report readers are charged per 30-minute session, with a maximum of $5.00 per reader per month. A free trial allows you to evaluate Amazon QuickSight without any charges. For more information, see Amazon QuickSight Pricing.

...

Amazon RDS

Amazon RDS makes it easy to set up, operate, and scale a relational database in the cloud. Amazon RDS is available on several database instance types (optimized for memory, performance, or I/O) and provides you with six familiar database engines to choose from, including Amazon Aurora, PostgreSQL, MySQL, MariaDB, Oracle Database, and SQL Server.

You should consider RDS when:

    You are building an operational data store
    You are migrating SQL Server or Oracle Database data warehouse to the cloud but are not interested in refactoring.
    Your query workload includes:
        Queries which acces highly-filtered data on tables that can easily be indexed.
        Analytics queries on small-to-medium sized tables (gigabytes)
        A mix of medium-complexity analytical queries and simple, highly-filtered queries used in Dashboards

When using Amazon RDS with Microsoft Power BI, keep the following points in mind:

    Amazon RDS provides multiple database engines including SQL Server, MariaDB, MySQL, Oracle Database, and PostgreSQL. Note that the database engines are listed in Power BI Desktop and Power BI service, not the Amazon RDS service.

    For Amazon Aurora, use the MySQL or PostgreSQL connection type, depending on your selected database engine.

    While an Amazon RDS instance can be launched in a public subnet and configured to allow access from the internet, the majority of customers prefer to launch it in a private subnet to increase security. When using a private subnet to make use of the on-premises data gateway to connect from the Power BI service to RDS.

    With Amazon RDS, you can deploy multiple editions of SQL Server (2012, 2014, 2016, 2017, and 2019) including Express, Web, Standard, and Enterprise.

Amazon Athena

Amazon Athena is an interactive query service that makes it easy to analyze data in Amazon S3 using standard SQL. Athena is out-of-the-box integrated with AWS Glue Data Catalog, allowing you to create a unified metadata repository across various services, crawl data sources to discover schemas, populate your Data Catalog with new and modified table and partition definitions, and maintain schema versioning.

You should consider Athena as a data source when:

    You want to query your data lake directly.
    Your query workload includes:
        Queries which compute aggregations on large (multi-gigabyte and multi-terrabyte) tables
        Interactive ad hoc SQL, for exploratory purposes.

When using Amazon Athena with Microsoft Power BI, keep the following points in mind:

    With the July 2021 release of Microsoft Power BI, a Microsoft-certified connector has been introduced for Amazon Athena. You can use the Microsoft Power BI connector fo Amazon Athena to analyze data from Amazon Athena in Microsoft Power BI Desktop. After you publish content to the Power BI service, you can use the Microsoft on-premises data gateway to keep the content up to date through on-demand or scheduled resources.

    The Microsoft Power BI connector for Amazon Athena supports both Import and Direct Query data connectivity modes. With the Import mode, selected tables and columns are imported into Power BI Desktop for querying. With Direct Query mode, no data is imported or copied into Power BI Desktop, and instead Power BI Desktop queries the underlying data source directly.

    For more information on the Microsoft Power BI connector for Amazon Athena, refer to Using hte Amazon Athena Power BI Connector.

    Note that the Microsoft Power BI Connector for Amazon Athena requries the use of the Amazon Athena OBDC driver and a valid ODBC DSN configuration on your system to query Amazon Athena. To download the latest OBDC driver and for configuration, refer to Connecting to Amazon Athena with OBDC.

    For a tutorial on the configuration steps and best practices when using the Microsoft Power BI connector for Amazon Athena, refer to creating dashboards quickly on Microsoft Power BI using Amazon Athena.

...

https://aws.amazon.com/blogs/devops/how-marketaxess-uses-aws-developer-tools-to-create-scalable-and-secure-ci-cd-pipelines/

How MarketAxess uses AWS Developer Tools to create scalable and secure CI/CD pipelines

Very often, enterprise organizations strive to adopt modern devops practices, to focus on goverance and security without sacrificing development velocity. In this guest post, Prashant Joshi, Senior Cloud Engineer at Market Axess, explains how they use the AWS Cloud Development Kit (AWS CDK), AWS CodePipeline, and AWS CodeBuild to simplify

...

https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/GettingStarted.Walkthrough.html
Get started

With the right template, you can deploy all at once all the AWS resources you need for an application. In this section, you'll examine a template that declares the resources for a WordPress blog, creates a WordPress block as a stack, monitors the stack creation processs, examines the resources on the stack, and then deletes the stack. You use the AWS Management Console to complete these tasks.

Step 1: Pick a template

First, you'll need a template that specifies the resources that you want in your stack. For this step, you use a sample template that's already prepared. The sample template creates a basic WordPress blog that uses a single Amaon EC2 instance with a local MySQL database for storage. The template also crates an Amazon EC2 security group to control firewall settings for the Amazon EC2 instance.

Important: AWS CloudFormation is free, but the AWS resources that CloudFormation creates are live (and not running in a sandbox). You will incur the standard usage fees for these resources until you terminate them in the last task of this tutorial. The total charges will be minimal. For information on how you might minimize any charges, go to http://aws.amazon.com/free/

To view the template

    You can view the JSON or YAML Wordpress sample template. You don't need to download it because you will use the template URL later in this guide. For more information about the template formats, see AWS CloudFormation template formats.

A template is a JSON or YAML text file that contains the configuration information about the AWS resources you want to create in the stack. For this walkthrough, the sample template includes six top-level sections: AWSTemplateFormatVersion, Description, Parameters, Mappings, Resources, and Outputs; however, only the Resources section is required.

The Resources template contains the definitions of the AWS resources you want to create with the template. Each resource is listed spearately and specifies the properties that are necessary for creating that particular resource. The following resource declaration is the configuration for the EC2 instance, which in this example ahs the logical name WebServer:

[sample json, sample yaml]

If you have created EC2 instances before, you recognize properties, such as ImageId, InstanceType, and KeyName, that determine the configuration of the instance. Resource declarations are an efficient way to specify all these configuration settings at once. When you put resource declarations in a template, you can create and configure all the declared resources by using the template to create a stack. Create a new stack that uses the same template to launch the same configuration of resources.

The resource declaration begins with a string that specifies the logical name for that resource. As you'll see, the logical name can be used to refer to resources within the template.

...

Step 4: Monitor the progress of stack creation

After you complete the Create Stack wizard, CloudFormation begins creating the resources that are specified in the template. Your new stack, MyWPTestStack appears in the list at the top portion of the CloudFormation console. Its status should be CREATE_IN_PROGRESS. You can see detailed status of a stack by viewing its events.

To view the events for the stack

    1. On the CloudFormation console, select the stack MyWPTestStack in the list.
    2. In the stack details page, choose the Events tab. The console automatically the event list with the most recent events every 60 seconds.

The Events tab displays each major step in the creation of the stack sorted by the time of each event, with latest events on top.

The first event (at the bottom of the event list) is the start of the stack creation process:

2013-04-24 18:54 UTC-7 CREATE_IN_PROGRESS AWS::CloudFormation::Stack MyWPTestStack User initiated

Next are events that mark the beginning and completion of each resource. For example, createion of the EC2 instance results in the following entries:

2013-04-24 18:59 UTC-7 CREATE_COMPLETE AWS::EC2::Instance...

2013-04-24 18:54 UTC-7 CREATE_IN_PROGRESS AWS::EC2::Instance...

The CREATE_IN_PROGRESS event is logged when CloudFormation reports that it has begun to create the resource. The CREATE_COMPLETE event is logged when the resource is successfully created.

When CloudFormation has successfully created the stack, you will see the following event at the top of the Events tab:

2013-04-24 19:17 UTC-7 CREATE_COMPLETE AWS::CloudForrmation::Stack MyWPTestStack

If CloudFormation can't create a resource, it reports a CREATE_FAILED event, and, by default, rolls back the stack and deltes any resources that have been created. The Status Reason column displays the issue that caused the failure.

https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/gettingstarted.templatebasics.html

Learn template basics:

In Get Started, you learned how to use a template to create a stack. You saw resources declared in a template and how they map to resources in the stack. We also touched on input parameters and how they enable you to pass specific values when you create a stack from a template. In this section, we'll go deeper into resources and parameters. We'll also cover the other components of templates so that you'll know how to use these components together to create templates that produce the AWS resources you want.

What is an AWS CloudFormation template?

A template is a declaration of the AWS resources that make up a stack. The template is stored as a text tile whose format complies with the JavaScript Object Notation (JSON) or YAML standard. Because they're text files, you can create and edit them in any text editor and manage them in your source control system with the rest of your source code. For more information about template formats, see AWS CloudFormation template formats.

In the tempalte, you declare the AWS resources you want to create and configure. You declare an object as a name-value pair or a paring of a name with a set of child objects enclosed. The syntax depends on the format you use. For more information, see the Template anatomy. The only required top-level object is the Resources object, which must declare at least one resource. Let's start with the most basic template containing only a Resources object, which contains a single resource declaration.

Resources: Hello Bucket!

The Resources object contains a list of resource objects. A resource declaration contains the resource's attributes, which are themselves declared as child objects. A resource must have a Type attribute, which defines the kind of AWS resource you want to create. The Type attribute has a special format.

AWS::ProductIdentifier::ResourceType

For example, the resource type for an Amazon S3 bucket is AWS::S3::Bucket. For a full list of resource types, see Template reference.

Let's take a look at a basic template. The following template declares a single resource of type AWS::S3::Bucket with the name HelloBucket.

...

Resource properties using resources together

Usually, a property for a resource is simply a string value. For example, the following tempalte specifies a canned ACL (PublicRead) for the AccessControl property of the bucket.

YAML:
Resources:
  HelloBucket:
  Type: 'AWS::S3::Bucket'
  Properties:
    AccessControl: PublicRead

Some resources have multiple properties, and some properties can have one or more subproperties. For example, the AWS::S3::Bucket resource has two properties: AccessControl and WebsiteConfiguration. The WebsiteConfiguration property has two subproperties: IndexDocument and ErrorDocument. The following template shows our original bucket resource with the additional properties.

YAML:

Resources:
  HelloBucket:
  Properties:
    AccessControl: PublicRead
    WebsiteConfiguration:
      IndexDocument: index.html
      ErrorDocument: error.html

One of the greatest benefits of templates and CloudFormation is the ability to create a set of resources that work together to create an application or solution. The name used for a resource within the template is a logical name. When CloudFormation creates a resource, it generates a physical name that's based on the combination of hte logical name, the stack name, and a unique ID.

You're probably wondergin how you set properties on one resource based on the name or property of another resource. For example, you can create a CloudFront distribution backed by an S3 bucket or EC2 instance that uses EC2 security groups, and all of those resources can be created in the same template. CloudFormation has a number of intrinsic functions that you can use to refer to other resources and their properties. You can use the Ref function to refer to an identifying property of a resource. Frequently, this is the physical name of the resource; however, sometimes it can be an identifier, such as an IP address for an AWS::EC2::EIP resource or an Amazon Resource Name (ARN) for an Amazon SNS topic. For a list of values returned by the Ref function, see Ref Function. The following template contains an AWS::EC2::Instance resource. The resource's SecurityGroups property calls the Ref function to refer to the AWS::EC2::SecurityGroup resource InstanceSecurityGroup.

YAML

Resources:
  Ec2Instance:
    Type: 'AWS::EC2::Instance'
    Properties:
      SecurityGroups:
        - !Ref InstanceSecurityGroup
      KeyName
  InstanceSecurityGroup:
    Type: 'AWS::EC2:SecurityGroup'
    Properties:
      GroupDescription: Enable SSH access via port 22
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0

The SecurityGroups property is a list of security groups, and in the previous example, we have only one item in the list. The following template has an additional item in the SecurityGroups property list.

YAML

Resources:
  Ec2Instance:
    Type: 'AWS::EC2::Instance'
    Properties
      SecurityGroups:
      - !Ref InstanceSecurityGroup
      - MyExistingSecurityGroup
    KeyName: mykey
    ImageId: ami-7a11e213
  InstanceSecurityGroup:
    Type: 'AWS::EC2:SecurityGroup'
    Properties:
      GroupDescription: Enable SSH access via port 22
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0

MyExistingSecurityGroup is a string that refers to an existing EC2 security group instead of a security group declared in a template. You use literal strings to referto existing AWS resources.

In the example above, the KeyName property of the AWS::EC2::Instance is the literal string mykey. This means that a key pair with the name mykey must exist in the region where the stack is being created; otherwise, stack creation will fail because the key pair doesn't exist. The key pair you use can vary with the region where you are creating the stack, or you may want to share the template with someone else so that they can use it in their AWS account. If so, you can use an input parameter so that the key pair name can be specified when the stack is created. The Ref function can refer to input parameters that are specified at stack creation time. The following template adds a Parameters object containing the KeyName parameter, which is used to specify the KeyName property for the AWS::EC2::Instance resource. The parameter type is AWS::EC2::KeyPair::KeyName, which ensures a user specifies a valid key pair name in his or her account and in the region whre the stack is being created.

YAML

Parameters:
  KeyName:
    Description: The EC2 Key Pair to allow SSH access to the instance
    Type: 'AWS::EC2::KeyPair::KeyName'
Resources:
  Ec2Instance:
    Type: 'AWS::EC2::Instance'
    Properties
      SecurityGroups:
      - !Ref InstanceSecurityGroup
      - MyExistingSecurityGroup
    KeyName: !Ref KeyName
    ImageId: ami-7a11e213
  InstanceSecurityGroup:
    Type: 'AWS::EC2:SecurityGroup'
    Properties:
      GroupDescription: Enable SSH access via port 22
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0

The Ref function is handy if the parameter or the value returned for a resource is exactly what you want; however, you may need other attributes of a resource. For example, if you want to create a CloudFront distribution with an S3 origin, you need to specify the bucket location by using a DNS-style address. A number of resources have additional attributes whose values you can use in your template. To get these attributes, you use the Fn::GetAtt function. The following tempalte creates a cloudformation distribution resource that specifies the DNS name of an S3 bucket resource using Fn:GetAtt function to get the bucket's DomainName attributes.

YAML

Resources:
  myBucket:
    Type: 'AWS::S3::Bucket'
  myDistribution:
    Type: 'AWS::CloudFront:Distribution'
    Properties:
      DistributionConfig:
        Origins:
          -  DomainName: !GetAtt
             - myBucket
             - DomainName
             Id: myS3Origin
             S3OriginConfig:{}
        Enabled: 'true'
        DefaultCacheBehavior:
          TargetOriginId: myS3Origin
          ForwardedValues:
            QueryString: 'false'
          ViewerProtocolPolicy: allow-all

The Fn::GetAtt function takes two parameters, the logical name of the resource and the name of the attribute to be retrieved. For a full list of available attributes for resources, see Fn::GetAtt. You'll notice that teh Fn::GetAtt function lists its two parameters in an array. For functions that take multiple parameters, you use an array to specify their parameters.

Receiving user input using input parameters

So far, you've learned about resources and a little bit about how to use them together within a template. You've learned how to refer to input parameters, but we haven't gone deeply into how to define the input parameters themselves. Let's take a look at parameter declarations and how you can restrict and validate user input.

You declare parameters in a template's Parameters object. A parameter contains a list of attributes that define its value and constraints against its value. The only requried attribute is Type, which can be String, Number, or an AWS-specific type. You can also add a Description attribute that tells a user more about what kind of value they should specify. The parameter's name and description appear in the Specify Parameters page when a user uses the template in the Create Stack wizard.

The following template fragment is a Parameters object that declares the parameters used in teh Speciy Parameters Page above.

JSON

"Parameters": {
    "KeyName":{
        "Description": "Name of an existing EC2 KeyPair to enable SSH access into the WordPress web server",
        "Type": "AWS::EC2::KeyPair::KeyName"
    },
    "WordPressUser":{
        "Default": "admin",
        "NoEcho": "true",
        "Description": "The WordPress database admin account user name",
        "Type": "String",
        "MinLength": "1",
        "MaxLength": "16",
        "AllowedPattern": "[a-zA-Z][a-zA-Z0-9]*"
    },
    "WebServerPort":{
        "Default": "8888",
        "Description": "TCP/IP port for the WordPress web server",
        "Type": "Number",
        "MinValue": "1",
        "MaxValue": "65535"
    }
}

For parameters with default values, CloudFormation uses the default values unless users speccify another value. If you omit the default attribute, users are required to specify a value for that parameter; however, requiring the user to input a value does nto ensure that the value is valid. To validate the value of the parameter, you can declare constraints or specify an AWS-specific parameter type.

You'll notice that the KeyName parameter has no Default attribtue and the other parameters do. For example, the WordPressUser parameter has the attribute Default: admin, but the KeyName attribute has none. Users must specify a key name at stack creation. If they don't CloudFormation fails to create the stack and throws an exception: Parameters: [KeyName] must have values

For AWS-specific parameter types, CloudFormation validates input values against existing values in the user's AWS account and in the region where they're createing the stack before creating any stack resources. In the sample template, the KeyName parameter is an AWS-specific parameter type of AWS::EC2::KeyPair::KeyName. CloudFormation checks that users specify a valid EC2 key pair name before creating the stack. Another example of an AWS-specific parameter type is AWS::EC2::VPC::Id, which requires users to specify a valid VPC ID. In addition to upfront validation, the AWS console shows a drop down list of valid values for AWS-specific parameter types, such as valid EC2 key pair names or VPC IDs, when the users use the Create Stack Wizard.

For the String type, you can use the following attributes to declare constraints: MinLength, MaxLength, Default, AllowedValues, and AllowedPattern. In the example above, the WordPressUser parameter has three consteraints: the parameter must be 1 to 16 characters long (MinLength, MaxLength) and must begin with a letter followed by any combination of letters and numbers (AllowedPattern).

For the Number type, you can declare the following constraints: MinValue, MaxValue, Default, and AllowedValues. A number can be an integer or a float value. In the example above, the WebServerPort parameter must be a number between 1 and 65535 inclusive (MinValue, MaxValue).

Earlier in this section, we mentioned that parameters are a good way to specify sensitive or implementation-specific data, such as passwords or user names, that you need to use but don't want to embed in the template itself. If you set the NoEcho attribute to true, CloudFormation returns the parameter value masked as asterisks (*****) for any calls that describe the stack or stack events, except for information stored in the locations specified below. In the example above, the WrodPressUser parameter value isn't visible to anyone viewing the stack's settings, and its value is returned as asterisks.

Important: Using the NoEcho attribute does not mask any information stored in the following:
    The Metadata template section. CloudFormation does not transform, modify, ore redact any information you include in the Metadata section. For more information, see Metadata.
    The Outputs template section. For more information, see Outputs
    The Metadata attribute of a resource definition. For more information, Metadata attribute.
We strongly recommend you do not use these mechanisms to include sensitive information, such as passwords or secrets.

Important: Rather than embedding sensitive information directly in your CloudFormation templates, we recommend you use dynamic parameters in the stack template to reference sensitive information that is stored and managed outside of CloudFormation, such as in the AWS Systems Manager Parameter Store or AWS Secrets Manager. For more information, see the Do not embed credentials in your templates best practice.

Specifying conditional values using mappings

Parameters are a great way to enable users to specify unique or sensitive values for use in the properties of stack resources; however, there may be settings that are region dependent or are somewhat complex for users to figure out because of other conditions and dependencies. In these cases, you would want to put some logic in the template itself so that users can specify simpler values (or none at all) to get the result that they want. In an earlier example, we hard-coded the AMI ID for the ImageId property of our EC2 instance. This works fine in the US-East region, where it represents the AMI we want. However, if the user tries to build the stack in a different region, they will get the wrong AMI or no AMI at all. (AMI IDs are unique to a region, so the same AMI ID in a different region may not represent any AMI or a completely different one.)

To avoid this problem, you need a way to specify the right AMI ID based on a conditional input (in this example, the region where the stack is created). There are two template features that can help, the Mappings object and the AWS::Region pseudo parameter.

The AWS::Region pseudo paramter is a value that CloudFormation resolves as the region where the stack is cretaed. Pseudo parameters are resolved by CloudFormation when you create the stack. Mappings enable you to use an input value as a condition that determines another value. Similar to a switch statement, a mapping associates one set of values with another. Using the AWS::Region parameter together with a mapping, you can ensure that an AMI ID appropriate to the region is specified. The following template contains a Mappings object with a mapping named RegionMap that's used to map an AMI ID to the appropriate region.

JSON
{
    "Parameters": {
        "KeyName":{
            "Description": "name of an existing EC2 keypair to enable SSH access to the instance",
            "Type", "String"
        }
    },
    "Mappings": {
        "RegionMap": {
            "us-east-1": {
                "AMI": "ami-760061f"
            },
            "us-west-1": {
                "AMI": "ami-655a0a20"
            },
            "eu-west-1": {
                "AMI": "ami-7fd4e10b"
            },
            "ap-southeast-1": {
                "AMI": "ami-72621c20"
            },
            "ap-northeast-1": {
                "AMI": "ami-8e08a38f"
            }
        }
    },
    "Resources": {
        "Ec2Instance": {
            "Type": "AWS::EC2::Instance",
            "Properties": {
                "Ref": "KeyName"
            },
            "ImageId": {
                "Fn::FindInMap": ["RegionMap", {
                "Ref": "AWS::Region"
                },
                "AMI"]
            },
            "UserData": {
                "Fn::Base64":"80"
            }
        }
    }
}

In the RegionMap, each region is mapped to a name-value pair. The name-value pair is a label, and the value to map. In the RegionMap, AMI is the label and AMI ID is the value. To use a map to return a value, you use to Fn::FindInMap function, passing teh name of the map, the value to be used to find the mapped value, and the label of the mapped value you want to return. In the example above, the ImageId property of the resource Ec2iInstance uses the Fn::FindInMap function to determine its value by specifying RegionMap as the map to use, AWS::Region as the input value to map from, and AMI as the label to identify the value to map to. For example, if this template were used to create a stack in US West (N. California) Region, ImageId would be set to ami-655a0a20.

Tip: The AWS::Region pseudo parameter enables you to get the region where the stack is created. Some resources, such as AWS::EC2::Instance, AWS::AutoScaling::AutoScalingGroup, and AWS::ElasticLoadBalancing::LoadBalancer, have a property that specifies availability zones. You can use the Fn::GetAZs function to get the list of all availability zones in a region.

Constructed values and output values

Parameters and mappings are an excellent way to pass to determine specific values at stack creation time, but there can be situations where a value from a parameter or other resource attribute is only part of the value you need. For example, in hte following fragment form the WordPress template, the Fn::Join function constructs the Target subproperty of the HealthCheck property for the ElasticLoadBalancer resource by concatenatnig the WebServerPort parameter with other literal strings to form the value needed.

JSON
{
    "Resources":{
        "ElasticLoadBalancer":{
            "Type",
            "Properties":{
                "AvailabilityZones": {
                    "Fn::GetAZs": ""
                },
                "Instances": [
                    {
                        "Ref": Ec2Instance1
                    },
                    {
                        "Ref": Ec2Instance2
                    }

                ],
                "Listeners":[
                    {
                    "LoadBalancerPort": "80",
                    "InstancePort":{
                        "Ref": WebServerPort"
                    },
                    "Protocol": "HTTP"
                    }
                ],
                "HealthCheck": {
                    "Target": {
                        "Fn::Join": ["",
                            [
                            "HTTP:",
                                {
                                "Ref": "WebServerPort"
                                },
                                "/"
                            ]]
                    },
                    "HealthyThreshold": "3",
                    "UnhealthyThreshold": "5",
                    "Interval": "30",
                    "Timeout": "5"
                }
            }
        }
    }
}

The Fn::Join function takes two parameters, a delimiter that separartes the valeus you want to concatenate and an array of values in the order that you want them to appear. In the example above, the Fn::Join function specifies an empty string as the delimeter and HTTP:, the value of the WebServerPort parameter, and a / character as the values to concatenate. If WebServerPort had a value of 8888, the Target property would be set to the following value:

HTTP:8888/

The Fn:Join function is also useful for declaring otuput values for the stack. The Outputs object in the template contains declarations for the values that you want to have available after the stack is created. An output is a convenient way to capture important information about your resources or input parameters. For example, in the WordPress template, we declare the following Output object.

JSON

{
    "Outputs": {
        "InstallURL": {
            "Value": {
                "Fn::Join" : [
                "",
                [
                    "http://",
                    {
                        "Fn:GetAtt": [
                            "ElasticLoadBalancer",
                            "DNSName"
                        ]
                    },
                    "/wp-admin/install.php"
                ]
                ]
            },
            "Description": "Installation URL of the WordPress Website"
        },
        "WebsiteURL":{
            "Value": {
                "Fn::Join": [
                    "",
                    [
                        "http://",
                        {
                            "Fn::GetAtt": [
                                "ElasticLoadBalancer",
                                "DNSName"
                            ]
                        }
                    ]
                ]
            }
        }
    }
}

Each output value has a name, a Value attribute that contains declaration of the value returned as the output value, and optionally a description of the value. In the previous example, InstallURL is the string returned by a Fn::Join function call that concatenates http://, the DNS name of the resource ElasticLoadBalancer, and /wp-admin/install.php. The output value would be similar to the following:

http://mywptests-elastic1-1gb51l6sl8y5v-20616572.us-east-2.elb.amazonaws.com/wp-admin/install.php

In the Get Started tutorial, we used this link to conveniently go to the installation page for the WordPres blog that we created. CloudFormation generates the output values after it finishes creating the stack. You can view output values in the Outputs tab of the CloudFormation console or by using the aws cloudformation describe-stacks command.

Next steps

We just walked through the basic parts of a template and how to use them. You learned the following about templates:

    Declaring resources and their properties.
    Referencing other resources with the Ref function and resource attributes using the Fn::GetAtt function.
    Using parameters to enable users to specify values at stack creation time using constraints to validate parameter input.
    Using mappings to determine conditional values.
    Using the Fn::Join function to construct values based on parameters, resource attributes, and other strings.
    Using output values to capture information about the stack's resources.

We didn't cover two top level objects in a template: AWSTemplateFormatVersion and Description. AWSTemplateFormatVersion is simply the version of the template format - if you don't specify it, CloudFormation will use the latest version.

The Description is any valid JSON or YAML string. This description appears in the Specify parameters page of the Create Stack Wizard. For more information, see Format version and Description.

Of course, there are more advanced template and stack feature. Here is a list of a few important ones you'll want to learn more about:

Optional attributes that can be used with any resource:

    DependsOn attribute enables you to specify that one resource must be created after another.
    DeletionPolicy attribute enables you to specify how CloudFormation should handle the deletion of a resource.
    Metadata attribute enables you to specify structured data with a resource.

AWS::CloudFormation::Stack enables you to nest another stack as a resource within your template.

https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/updating.stacks.walkthrough.html

Walkthrough: Updating a stack

With AWS CloudFormation, you can update the properties for resources in your existing stacks. These changes can range from simple configuration changes, such as updating the alarm threshold on a CloudWatch alarm, to more complex changes, such as updating the Amazon Machine Image (AMI) running on an Amazon EC2 instance. Many of the AWS resources in a template can be updated, and we continue to add support for more.

This section walks through a simple progreession of updates of a running stack. It shows how he use of templates makes it possible to use a version control system for the configuration of your AWS infrastructure, just as you use version control for the software you are running. We will walk through the following steps:

    1. Create the initial stack - create a stack using a base Amazon Linux AMI, installing the Apache Web Server and a simple PHP application using the AWS CloudFormation helper scripts.

    2. Update the application - update one of the files in the application and deploy the software using CloudFormation.

    3. Update the instance type - Change the instance type of the underlying Amazon EC2 instance.

    4. Update the AMI on an Amazon EC2 instance - Change the Amazon Machine Image (AMI) for the Amazon EC2 instance in your stack.

    5. Add a key pair to the instance - add an Amazon EC2 key pair to the instance, and then update the security group to allow SSH access to the instance.

    6. Change the stack's resources - add and remove resources from the stack, converting it to an auto-scaled, load-balanced application by updating the template.

A simple application

We'll begin by creating a stack that we can use throughout the rest of the section. We have promised a simple template that launches a single instance PHP web application hosted on hte Apache Web Server and running on an Amazon Linux AMI.

The Apache Web Server, PHP, and the simple PHP application are all installed by the CloudFormation helper scripts that are installed by default on the Amazon Linux AMI. The following template snippet shows the metadata that describes the packages and files to install, in this case the Apache Web Server and the PHP infrastructure from the Yum repository for the Amazon Linux AMI. The snippet also shows the Services section, which ensures that the Apache Web Server is running. In the Properties section of the Amazon EC2 instance definition, the UserData property contains the CloudInit script that calls cfn-init to install the packages and files.

"WebServerInstance": {
    "Type" : "AWS::EC2::Instance",
    "Metadata" : {
        "AWS::CloudFormation::Init" : {
            "config" : {
                "packages": {
                    "yum" : {
                        "httpd"    : [],
                        "php"      : []
                        }
                    }
                }
            "files": {

                "/var/www/html/index.php" : {
                    "content" : {"Fn:Join" : ["",[
                        "<?php\n",
                        "echo '<h1> AWS CloudFormation sample PHP application </h1>';\n",
                        "echo '<p>", {"Ref" : "WelcomeMessage"}, "</p>';\n",
                    ]]},
                    "mode" : "000644",
                    "owner" : "apache",
                    "group" : "apache"
                },
            },

            :
            "services":{
                "sysvinit" : {
                    "httpd" : {"enabled":"true", "ensureRunning": "true"}
                }
            }
            }
        },
        "Properties": {
        :
        "UserData" : {"Fn::Base64": {Fn::Join" : ["", ["#!/bin/bash\n",
            "yum install -y -aws-cfn-bootstrap\n",
            :
            "# Install the fiels and packages from the metadata \n",
            "/opt/aws/bin/cfn-init -v",
            "    --stack", {"Ref": "AWS::StackName"},
            "    --resource WebServiceInstance",
            "    --region", {"Ref": "AWS::Region"}, "\n"
        ]]}}
        }
},

The application itself is a two-line "Hello World" example that's entirely defined within the template. For a real-world application, the files may be stored on Amazon S3, GitHub, or another repository referenced from the template. CloudFormation can download packages (such as RPMs or RubyGems), and reference individual files and expand .zip and .tar files to create the application artifacts on the Amazon EC2 instance.

The template enables and configures the cfn-hup daemon to listen for changes to the configuration defined in the metadata for the Amazon EC2 instance. By using the cfn-hup daemon, you can update application software, such as the version of Apache or PHP, or you can update the PHP application file itself from AWS CloudFormation. The following snippet from the same Amazon EC2 resource in the template shows the pieces necessary to configure cfn-hup to call cfn-init to update the software if any changes to the metadata are detected:

"WebServerInstance": {
    "Type": "AWS::EC2::Instance",
    "Metadata" : {
        "AWS::CloudFormation::Init" : {
            "config" : {

                :

                "files" : {

                    :

                    "/etc/cfn/cfn-hup.conf" : {
                        "content" : { "Fn::Join" : ["", [
                            "[main]n\",
                            "stack=", {"Ref": "AWS::StackName"}, "\n",
                            "region=", {"Ref": "AWS::Region"}, "\n"
                        ]]
                        },
                        "mode": "000400",
                        "owner": "root",
                        "group": "root"
                    },

                    "/etc/cfn/hooks.d/cfn-auto-reloader.conf" : {
                        "content" : {"Fn::Join": ["",[
                            "[cfn-auto-reloader-hook]\n",
                            "triggers=post.update\n",
                            "path=Resources.WebServerInstance.Metadata.AWS::CloudFormation::Init\n",
                            "--region    ", {"Ref": "AWS::Region"}, "\n",
                            "runas=root\n"
                        ]]}
                    }
                },
                :

            },
            "Properties" : {

                :

                "UserData" : {"Fn::Base64": {"Fn::Join" [:, [

                    :

                    "#Start up teh cfn-hup daemon to listen for changes to the web server metadata\n",
                    "/opt/aws/bin/cfn-hup || error_exit 'Failed to start cfn-hup'\n",

                    :

                ]]}}
            }
        }
    },
}

To complete the stack, the template creates an Amazon EC2 security group.

...

This example uses a single Amazon EC2 instance, but you can use the same mechanisms on mroe complex situations that make use of Elastic Load Balancing and Amazon EC2 Auto Scaling groups to manage a collection of application servers. There are, however, some special considerations for Auto Scaling groups. For more information, see Updating Auto Scaling groups.

Create the initial stack

For the purposes of this example, we'll use the AWS Management Console to create an initial stack from the sample template.

Warning: Completing this procedure will deploy live AWS services. You will be charged to standard usage rates as long as these services are running.

To create the stack from the AWS Management Console

    1. Copy the previous template and save it locally on your system as a text file. Note the location because you'll need to use the file in a subsequent step.

    2. Log into the Console at...

    3. Choose Create New Stack

    4. In the Create New Stack wizard, on the Select Template screen, type UpdateTutorial in the Name field. On the same page, select Upload a template to Amazon S3 and browse to the file you downloaded in the first step, and then choose Next.

    5. On the Security Parameters screen, in the Instance Type box, type t1.micro. Then choose Next.

    6. On the Options screen, choose Next.

    7. On the Review screen, verify that all the settings are as you want them, and then choose create.

After the status of your stack is CREATE_COMPLETE, the output tab will display the URL of your website. If you choose the value of the WebsiteURL output, you will see your new PHP application working.

Update the application

Now that we have deployed the stack, let's update the application. We'll make a simple change to the text that's printed out by the applcation. To do so, we'll add an echo command to the index.php file as showsn in this template snippet:

"WebServerInstance": {
    "Type" : "AWS::EC2::Instance",
    "Metadata" : {
        "AWS::CloudFormation::Init" : {
            "config" : {
                :
                "files" : {
                    "/var/www/html/index.php" : {
                        "content" : {"Fn::Join" : ["", [
                            "<?php\n",
                            "echo '<h1>AWS CloudFormation sample PHP application <h1>';\n",
                            "echo '<p>Updated version via UpdateStack</p>'\n",
                            "?>\n"
                        ]]},
                        "mode" : "000644",
                        "owner" : "apache",
                        "group" : "apache"
                    },

                    :


                }
            }
        },
    }
}

Use a text editor to manually edit the template file that you saved locally.

Now, we'll update the stack.

To update teh stack from the AWS Management Console

    1. Log into the AWS CloudFormation console at: ...

    2. On the AWS CloudFormation dashboard, choose the stack you created previously, and then choose Update Stack.

    3. In the UpdateStack wizard, on the Select Template screen, select Upload a template to Amazon S3, select the modified template, and then choose Next.

    4. On the Options screen, choose Next.

    5. Choose Next because the stack doesn't have a stack policy. All resources can be updated without an overriding policy.

    6. On the Review screen, verify that all the sttings are as you want them, and then choose Update.

If you update the stack from the AWS Management Console, you will notice that the parameters that were used to create the initial stack are prepopulated on the Parameters page of the Update Stack wizard. If you use the aws cloudformation update-stack command, be sure to type in the same values for the parameters that you used originally to create the stack.

When your stack is in the UPDATE_COMPLETE state, you can choose the WebsiteURL output value again to verify that the changes to your application have taken effect. By default, the cfn-hup daemon runs every 15 minutes, so it may take up to 15 minutes for the application to change once the stack has been updated.

To see the set of resources that were updated, go to the AWS CloudFormation console. On the Events tab, look at the stack events. In this particular case, the metadata for the Amazon EC2 instance WebServerInstance was updated, which causes AWS CloudFormation to also reevaluate the other resources (WebServerSecurityGroup) to ensure that there were no other changes. None of the other stack resources were modified. AWS CloudFormation will update only those resources in the stack that are affected by any other changes to the stack. Such changes can be direct, such as property or metadata changes, or they can be due to dependencies or data flows through Ref, GetAtt, or other intrinsic template functions.

This simple update illustrates the process; however, you can make much more complex changes to the files and packages that are deployed to your Amazon EC2 instances. For example, you might decide that you need to add MySQL to the instance, along with PHP support for MySQL. To do so, simply add the additional packages and files along with any additional services to teh configuration and then upgrade the stack to deploy the changes. In the followign template snippet, teh changes are highlighted in red.

...

You can update the CloudFormation metadata to update to new versions of the packages used by the application. In the previous examples, the version property for each package is empty, indicating that cfn-init should install the latest version of that package.

"packages" : {
    "yum" : {
        "httpd"    : [],
        "php"      : []
    }
}

You can optionally specify a version string for a package. If you change the version string in subsequent update stack calls, the new version of the package will be deployed. Here's an example of using version numbers for RubyGem packages. Any package that supports versioning can have specific versions.

"packages" : {
    "rubygems" : {
        "mysql" : [],
        "rubygems-update" : ["1.6.2"],
        "rake" : ["0.8.7"],
        "rails" : ["2.3.11"]
    }
}

Updating Auto Scaling Groups

If you're using Auto Scaling groups in your template, as opposed to Amazon EC2 instance resources, updating the application will work exactly the same way; however, AWS CloudFormation doesn't provide any synchronization or serialization across the Amazon EC2 instances in an ASG. the cfn-hup daemon on each host will run independently and update the application, each instance will run the cfn-hup hooks on its own schedule; there's no coordination between the instances in the stack. You should consider the following:

    if the cfn-hup changes run on all Amazon EC2 instances in the Auto Scaling group at the same time, your service might be unavailable during the update.

    If the cfn-hup changes run at different times, old and new versions of the software may be running at the same time.

To avoid these issues, consider forcing a rolling update on your instances in the Auto Scaling group. For more information, see UpdatePolicy attribute.

Changing resource properties

With AWS CloudFormation, you can change the properties of an existing resource in the stack. The following sections describe various updates that solve specific problems; however, any property of any resource that supports updating in the stack can be modified as necessary.

Update the instance type

The stack we have built so far uses a t1.micro Amazon EC2 instance. Let's suppose that your newly created website is getting more traffic than a t1.micro instance can handle, and now you want to move to an m1.small Amazon EC2 instance type. If the architecture of the isntance type changes, the instance will be created with a different AMI. If you check out the mappings in the template, you will see that both the t1.micro and m1.small are the same architectures and use the same Amazon Linux AMIs.

...

Let's use the template that we modified in the previous section to change the instance type. Because InstanceType was an input parameter to the template, we don't need to modify the template; we can change the value of the parameter in the Stack Update wizard, on the Specify Parameters page.

To update the stack from the AWS Management Console

    1. Log ino the AWS CloudFormation console at...
    2. On the CloudFormation dashboard, choose the stack you created previously, and then choose Update Stack.
    3. In the Update Stack wizard, on the Select Template screen, select Use current template, and then choose Next. The Specify Details page appears with the parameters that were used to create the initial stack are pre-populated in the Specify Parameters section.
    4. Change the value of the InstanceType text box from t1.micro to m1.small. Then choose next.
    5. On the Options screen, choose next.
    6. Choose Next because the stack doesn't have a stack policy. All resources can be updated without an overriding policy.
    7. On the Review screen, verify that all the settings are as you want them, and then choose Update.

You can dynamically change the instance type of an EBS-backed Amazon EC2 instance by starting and stopping the instance. AWS CloudFormation tries to optimize the change by updating the instance type and restarting the instance, so the instance ID doesn't change. When the instance is restarted, however, the public IP address of the instance doesn't change. To ensure that the Elastic IP address is bound correctly after the change, AWS CloudFormation will also update the Elastic IP address. You can see the changes in the AWS CloudFormation console in the Events tab.

To check the instance type from the AWS Management Console, open the Amazon EC2 console, and locate your instance there.

Update the AMI on an Amazon EC2 instance

Now let's look at how we might change the Amazon Machine Image (AMI) running on the instance. We will initiate the AMI change by updating the stack to use a new Amazon EC2 instance type, such as t2.medium, which is an HVM64 instance type.

As in the previous section, we'll use our existing template to change the instance type used by our example stack. In the Stack Update wizard, on the Specify Parameters page, change the value of the Instance Type.

In this case, we can't simply start and stop the instance to modify the AMI; AWS CloudFormation considers this a change to an immutable property of the resource. In order to make a change to an immutable property of the resource. In order to make a change to an immutable property, AWS CloudFormation must launch a replacement resource, in this case a new Amazon EC2 instance running the new AMI.

After the new instance is running, AWS CloudFormation updates the other resources in teh stack to point to the new resource. When all new resources are created, the old resources are deleted, a proces known as UPDATE_CLEANUP. This time, you will notice that the instance ID and application URL of the instance in the stack has changed as a result of the update. The events in the Event table contain a description "Requested update has a change to an immutable property and hence creating a new physical resource" to indicate that a resource was replaced.

If you have application code written to the AMI that you want to update, you can use the same stack update mechanism to update the AMI to load your new application.

To update the AMI for an instance on your stack

    1. Create your new AMIs containing your application or operating system changes. For more information, go to Creating your own AMIs in the Amazon EC2 User Guide for Linux instances.
    2. Update your template to incorporate the new AMI IDs.
    3. Update the stack, either from the AWS Management Console as explained in Update the application or by using hte AWS command aws cloudformation update-stack.

When you update the stack, CloudFormation detects that the AMI ID has changed, and then it triggers a stack update in the same way as we initiated the one above.

Update the Amazon EC2 launch configuration for an Auto Scaling group

If you are using Auto Scaling groups rather than Amazon EC2 instances, the processes of updating the running instances is a little different. With Auto Scaling resources, the configuration of the Amazon EC2 instances, such as the instance type or the AMI ID is encapsulated in the Auto Scaling launch configuration. You can make changes to the launch configuration in the same way as we made changes to the Amazon EC2 instance resources in the previous sections. However, changing the launch configuration doesn't impact any of the running Amazon EC2 instances in the Auto Scaling group. An updated launch configuration applices only to new instances that are created after the update.

If you want to propagate the change to your launch configuration across all the instances in your Auto Scaling group, you can use an update attribute. For more information, see UpdatePolicy attribute.

Adding resource properties

So far, we've looked at changing existing properties of a resource in a template. You can also add properties that weren't originally specified in the template. To illustrate that, we'll add an Amazon EC2 key pair to an existing EC2 instance and then open up port 22 in the Amazon EC2 Security Group so that you can use Secure Shell (SSH) to access the instance.

Add a key pair to an instance

To add SSH access to an existing Amazon EC2 instance

    1. Add two additional parameters to the template to pass in the name of an existing Amazon EC2 key pair and SSH location.

    "Parameters": {
        "KeyName" : {
            "Description" : "Name of an existing Amazon EC2 key pair for SSH access",
            "Type" : "AWS::EC2::KeyPair::KeyName"
        },
        "SSHLocation" : {
            "Description" : "The IP address range that can be used to SSH into the EC2 instance",
            "Type" : "String",
            "MinLength" : "9",
            "MaxLength" : "18",
            "Default" : "0.0.0.0/0",
            "AllowedPattern" : "(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})/(\\d{1,2})",
            "ConstraintDescription" : "must be a valid IP CIDR range of the form x.x.x.x/x."
        }
        :
    },

    2. Add the KeyName property to the Amazon EC2 instance.

    ...

    3. Add port 22 and the SSH location to the ingress rules for the Amazon EC2 security group.

    ...

    4. Update the stack, either from the AWS Management Consolde as explained in Update the application or by using the AWS command aws cloudformation update-stack.

Change the stack's resources

Application needs can change over time, AWS CloudFormation allows you to change the set of resources that make up a stack. To demonstrate, we'll take the single instance application from Adding resource properties and convert it to an auto scaled, load-balanced application by updating the stack.

This will create a simple, single instance PHP application using an Elastic IP address. We'll now turn the application into a highly avialable, auto scaled, load balanced application by changing its resources during an update.

1. Add an Elastic Load Balancer resource.

    "ElasticLoadBalancer" : {
        "Type" : "AWS::ElasticLoadBalancer::LoadBalancer",
        "Properties" : {
            "CrossZone" : "true",
            "AvailabilityZones" : {"Fn::GetAZs" : ""},
            "LBCookieStickinessPolicy" : [ {
                "PolicyName" : "CookieBasedPolicy",
                "CookieExpirationPeriod" : "30"
            } ],
            "Listeners" : [ {
                "LoadBalancerPort" : "80",
                "InstancePort" : "80",
                "Protocol" : "HTTP",
                "PolicyNames" : [ "CookieBasedPolicy" ]
            } ],
            "HealthCheck" : {
                "Target" : "HTTP:80/",
                "HealthyThreshold" : "2",
                "UnhealthyThreshold" : "5",
                "Interval" : "10",
                "Timeout" : 5
            }
        }
    }

2. Convert the EC2 instance in the template into an Auto Scaling Launch Configuration. The properties are identical, so we only need to change the type name from:

    "WebServerInstance": {
        "Type" : "AWS::EC2::Instance",
    }

to:

    "LaunchConfig": {
        "Type" : "AWS::AutoScaling::LaunchConfiguration",
    }

For clarity in the template, we changed the name of the resource from WebServerInstance to LaunchConfig, so you'll need to update the resource name referenced by cfn-init and cfn-hup (just search for WebServerInstance and replace it with LaunchConfig, except for cfn-signal). For cfn-signal, you'll need to signal the Auto Scaling group (WebServerGroup) no the instance, as shown in the following snippet:

    "# Signal the status from cfn-init\n",
    "/opt/aws/bin/cfn-signal -e $? ",
    "       --stack", {"Ref" : "AWS::StackName"},
    "       --resource WebServerGroup",
    "       --region", {"Ref" : "AWS::Region"}, "\n"

3. Add an Auto Scaling group resource.

    "WebServerGroup" : {
        "Type" : "AWS::AutoScalingGroup::AutoScalingGroup",
        "Properties"
        ...
    }

4. Update the Security Group definition to lock down the traffic to the instances from the load balancer.

...

5. Update the Outputs to return the DNS Name of the Elastic Load Balancer as the location of the application from:

========================================================================

https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Internet_Gateway.html

Connect to the internet using an internet gateway

An internet gateway is a horizontally scaled, redundant, and highly available VPC component that allows communication between your VPC and the internet. An internet gateway enables resources (like EC2 instances) in your public subnets to connect to the internet if the resources has a public IPv4 address or an IPv6 address. Similarly, resources on the internet can initiate a connection to resources in your subnet using the public IPv4 address or IPv6 address. For example, an internet gateway enables you to connect to an EC2 instance in AWS using your local computer.

An internet gateway serves two purposes: to provide a target in your VPC route tables for internet-routeable traffic, and to perform network address translation (NAT) for instances that have been assigned public IPv4 addresses. For more information, see Enable internet access.

An internet gateway supports IPv4 and IPv6 traffic. It does not cause availability risks or bandwidth constraints on your network traffic. There's no additional charge for having an internet gateway in your account.

Enable internet access

To enable access to or from the internet for instances in a subnet in a VPC, you must do the following.

    Create an internet gateway and attach it to your VPC.
    Add a route to your subnet's route table that directs internet-bound traffic to the internet gateway.
    Ensure that instances in your subnet have a globally unique IP address (public IPv4 address, Elastic IP address, or IPv6 address).
    Ensure that your network access control lists and security group rules allow hte relevant traffic to flow to and from your instance.

Public and private subnets

If a subnet is associated with a route table that has a route to an internet gateway, it's known as a public subnet. If a subnet is associated with a route table that does not have a route to an internet gateway, it's known as a private subnet.

In your public subnet's route table, you can specify a route for the internet gaetway to all destinations not explicitly known to the route table (0.0.0.0/0 for IPv4 or ::/0 for IPv6). Alternatively, you can scope the route to a narrower range of IP addresses, for example, the public IPv4 address of your company's public endpoints outside of AWS, or the Elastic IP addresses of other Amazon EC2 instances outside your VPC.

IP addresses and NAT

To enable communication over the internet for IPv4, your instance must have a public IPv4 address or an elastic IP address that's associated with a private IPv4 address on your instance. Your instance is only aware of the private (internal) IP address space defined within the VPC and the subnet. The internet gateway logically provides the one-to-one NAT on behalf of your instance, so that when traffic leaves your VPC subnet and goes to the internet, the reply address field is set to the public IPv4 address or Elastic IP address of your instance, and not its private IP address. Conversely, Traffic that's destined for the public IPv4 address or Elastic IP address of your instance has its destination address translated to the instance's private IPv4 address before the the traffic is delivered to the VPC.

To enable communication over the internet for IPv6, your VPC and subnet must have an associated IPv6 CIDR block, and your instance must be assigned an IPv6 address from the range of the subnet. IPv6 addresses are globally unique, and therefore public by default.

In the following diagram, the subnet in Availability Zone A is a public subnet. The route table for this subnet has a route that sends all internet-bound IPv4 traffic to the internet gateway. The instances in the public subnet must have public IP addresses or Elastic IP addresses to enable communication with the internet over the internet gateway. For comparison, the subnet in Availability Zone B is a privaate subnet because its route table does not have a route to the internet gateway. Instances in the private subnet can't communicate with the internet over the internet gateway, even if they have public IP addresses.

To provide your instances with internet access without assigning them public IP addresses, you can use a NAT device instead. A NAT device enables instances in a private subnet to connect to the internet, but prevents hosts on the internet from initiating connections with the instances. For more information, see Connect to the internet or other networks using NAT devices.

Internet access fo default and nondefault VPCs

The following table provides an overview of whether your VPC automatically comes with the components required for internet access over IPv4 and IPv6.

Internet Gateway
    Default VPC: Yes
    Nondefault VPC: yes, if you created the VPC using the first or second option in the VPC wizard. Otherwise, you must manually create and attach the internet gateway.
Route table with route to internet gateway for IPv4 traffic (0.0.0.0/0)
    Default VPC: Yes
    Nondefault VPC: Yes, if you created the VPC using the first or second option in the VPC wizard. Otherwise, you must manually create the route table and add the route.
Route table with route to internet gateway for IPv6 traffic (::/0)
    Default VPC: No
    Nondefault VPC: Yes, if you created the VPC using the first or second option in the VPC wizard, and if you specified the option to associate an IPv6 CIDR block with the VPC. Otherwise, you must manually create the route table and add the route.

...

Create and attach an internet gateway

After you create an internet gateway, attach it to your VPC.

To create an internet gateway and attach it to your VPC

    1. Open the Amazon VPC console at https://console.aws.amazon.com/vpc/
    2. In the navigation pane, choose Internet Gateways, and then choose Create Internet gateway.
    3. Optionally name your internet gateway.
    4. Optionally add or remove a tag.
        [Add a tag] Choose Add tag and do the following:
            For Key, enter the key name.
            For Value, enter the key value.
        [Remove a tag] Choose Remove to the right of the tag's Key and Value.
    5. Choose Create internet gateway.
    6. Select the internet gateway that you just created, and then choose Actions, Attach to VPC.
    7. Select your VPC from the list, and then choose Attach internet gateway.

Create a custom route table

When you create a subenet, we automatically associate it with the main route tabel for the VPC. By default, the main route table doesn't contain a route to an internet gateway. The following procedure creates a custom route table with a route that sends traffic destined outside the VPC to the internet gateway, and then associates it with your subnet.

To create a custom route table

    1. Open the Amazon VPC console at https://console.aws.amazon.com/vpc/
    2. In the navigation pane, choose Route Tables, and then choose Create route table.
    3. In the Create route table dialog box, optionally name your route table, then select your VPC, and then choose Create route table.
    4. Select the custom route table that you just created. The details pane displays tabs for working with its routes, associations, and route propagation.
    5. On the Routes tab, choose Edit routes, Add route, and add the following routes as neccessary. Choose Save changes when you're done.
        For IPv4 traffic, specify 0.0.0.0/0 in the Destination box, and select the internet gateway ID in the target list.
        For IPv6 traffic, specify ::/0 in the Destination box, and select the internet gateway ID in the Target list.
    6. On the Subnet associations tab, choose Edit subnet associations, select the check box for the subnet, and choose Save associations.

For more information, see Configure route tables.

...

======================================================================================
https://docs.aws.amazon.com/vpc/latest/userguide/vpc-eips.html

Associate Elastic IP addresses with resources in your VPC

An Elastic IP address is a static, public IPv4 address designed for dynamic cloud computing. You can associate an Elastic IP address with any instance or network interface in any VPC in your account. With an Elastic IP address, you can mask the failure of an instance by rapidly remapping the address to another instance in your VPC.

Elastic IP address concepts and rules

To use an Elastic IP address, you first allocate it for use in your account. Then, you can associate it withn an instance or network interface in your VPC. Your Elastic IP address remains allocated to your AWS account until you explicitly release it.

An Elastic IP address is a property of a network interface. You can associate an Elastic IP address with an instance by updating the network interface attached to the instance. The advantage of associating the Elastic IP address with the network interface instead of directly with the instance is that you can move all the attributes of the network interface from one instance to another in a single step. For more information, see Elastic Network interfaces in the Amazon EC2 User guide for Linux instances.

The following rules apply:

    An Elastic IP address can be associated with a single instance or network interface at a time.

    You can move an Elastic IP address from one instance or network interface to another.

    If you associate an Elastic IP address with the eth0 network interface of your instance, its current public IPv4 address (if it had one) is released to the EC2-VPC public IP address pool. If you disassociate the Elastic IP address, the eth0 network interface is automatically assigned a new public IPv4 address within a few minutes. This doesn't apply if you've attached a second network interface to your instance.

...

Work with Elastic IP addresses

The following sections describe how you can work with Elastic IP addresses.

Tasks
    Allocate an Elastic IP address.
    Associate an Elastice IP address View your Elastic IP address
    View your Elastic IP address
    Disassociate an Elastic IP address
    Release an Elastic IP address
    Recover an Elastic IP address

Allocate an Elastic IP address

Before you use an Elastic IP, you must allocate one for use in your VPC.

To allocate an Elastic IP address

    1. Open the Amazon VPC console at https://console.aws.amazon.com/vpc/
    2. In the navigation pane, choose Elastic IPs.
    3. Choose Allocate Elastic address.
    4. For Public IPv4 address pool choose one of the following:
        Amazon's pool of IP addresses--If you want an IPv4 address to be allocated from Amazon's pool of IP addresses.
        My pool of public IPv4 addresses--If you want to allocate an IPv4 address from an IP address pool that you have brought to your AWS account. This option is disabled if you do not have any IP adress pools.
        Customer owned pool of IPv4 addresses--If you want to allocate an IPv4 address from a pool created fromm your on-premises network for use with an Outpost. This option is only available if you have an Outpost.
    5. (Optional) Add or remove a tag.
    ...
    6. Choose Allocate

Note: If you account supports EC2-Classic, first choose VPC.

===============================================

https://docs.aws.amazon.com/vpc/latest/tgw/what-is-transit-gateway.html

What is a transit gateway?

A transit gateway is a network transit hub that you can use to interconnect your virtual private clouds (VPCs) and on-premises networks. As your cloud infrastructure expands globally, inter-Region peering connects transit gateways together using the AWS Global infrastructure. Your data is automatically encrypted and never travels over the public internet.

For more information, see AWS Transit Gateway.

Transit gateway concepts

The following are the key concepts for transit gateways:

    Attachments--You can attach the following:
        One or more VPCs
        A Connect SD-WAN/third-party network appliance
        An AWS Direct Connect gateway
        A peering connection with another transit gateway
        A VPN connection to a transit gateway

    Transit gateway Maximum Transmission Unit (MTU)--The maximum transmission unit (MTU) of a network connection is the size, in bytes, of the largest permissible packet that can be passed over the connection. The larger the MTU of a connection, the more data that can be passsed in a single packet. A transit gateway supports an MTU of 8500 bytes for traffic between VPCs, AWS Direct Connect, Transit Gateway Connect, and peering attachments. Traffic over VPN connections can have a MTU of 1500 bytes.

...

https://docs.aws.amazon.com/vpc/latest/tgw/how-transit-gateways-work.html

How transit gateways work

A transit gateway acts as a Regional virtual router for traffic flowing between your virtual private clouds (VPCs)and on-premises networks. A transit gateway scales elastically based on the volume of network traffic. Routing through a transit gateway operates at layer 3, where packets are sent to a specific next-hop attachment, based on their destination IP addresses.

Contents

    Architecture diagram
    Resource Attachments
    Availability Zones
    Routing

Architecture diagram

The following diagram shows a transit gateway with three VPC attachments. The route table for each of these VPCs includes the local route and routes that send traffic destined for the other two VPCs to the transit gateway.

The following is an example of a default ransit gateway route table for the attachments shown in the previous diagram. The CIDR blocks for each VPC propagate to the route table. Therefore, each attachment can route packets to the other two attachments.

Destination | Target | Route type
VPC A CIDR | Attachment for VPC A | propagated
VPC B CIDR | Attachment for VPC B | propagated
VPC C CIDR | Attachment for VPC C | propagated

Resource attachments

A transit gateway attachment is both a source and a destination of packets. You can attach the following resources to your transit gateway:

    One or more VPCs. AWS Transit Gateway deploys an elastic network interface within VPC subnets, which is then used by the transit gateway to route traffic to and from the chosen subnets. You must have at least one subnet for each Availability Zone, which then enables traffic to reach resources in every subnet of that zone. During attachment creation, resources within a particular Availability Zone can reach a transit gateway only if a subnet is enabled within the same zone. If a subnet route table includes a route to the transit gateway, traffic is only forwarded to the transit gateway if the transit gateway has an attachment in the subnet of the same Availability Zone.

    One or more VPC connections
    One or more AWS Direct Connect gateways
    One or more Transit Gateway Connect attachments
    One or more transit gateway peering connections

    Intra-region peering connections are supported. You can have different transit gateways in different Regions.

Availability Zones

When you attach a VPC to a transit gateway, you must enable one or more Availability Zones to be sued by the transit gateway to route traffic to resources in the VPC subnets. To enable each Availability Zone, you specify exactly one subnet. The transit gateway places a network interface in that subnet using one IP address from that subnet. After you enable an Availability Zone, traffic can be routed to all subnets in that zone, not just the specified subnet. Resources that reside in Availability Zones where there is no transit gateway attachment cannot reach the transit gateway.

We recommend that you enable multiple Availability Zones to ensure availability.

Using appliance mode support

If you plan to configure a stateful network appliance in your VPC, you can enable appliance mode support for that VPC attachment in which the appliance is located. This ensures that the transit gateway uses the same Availability Zone for that VPC attachment for the lifetime of a flow of traffic between source and destination. It also allows the transit gateway to send traffic to any Availability Zone in the VPC, as long as there is a subnet association in that zone. For more information, see Example: Appliance in a shared services VPC.

Routing

Your transit gateway routes IPv4 and IPv6 packets between attachments using transit gateway route tables. You can configure these route tables to propagate routes from the route tables for the attached VPCs, VPN connections, and Direct Connect gateways. You can also add static routes to the transit gateway route tables. When a packet comes from one attachment, it is routed to another attachment using the route that matches the destination IP address.

For transit gateway peering attachments, only static routes are supported.

Contents
    Route Tables
    Route table association
    Route propagation
    Routes for peering attachments
    Route evaluation order

Route tables

Your tranist gateway automatically comes with a default route table. By default, this route table is the default association route table and the default propagation route table. Alternatively, if you disbale route propagation and route table association, AWS does not create a default route table for the transit gateway.

You can create additional route tables for your transit gateway. This enables you to isolate subnets of attachments. Each attachment can be associated with one route table. An attachment can propagate its routes to one or more route tables.

You can create a blackhole route in your transit gateway route table that drops traffic that matches the route.

When you attach a VPC to a transit gateway, you must add a route to your subnet route table in order for traffic to route through the transit gateway. For more information, see Routing for a Transit Gateway in the Amazon VPC User Guide.

Route table association

You can associate a transit gateway attachment with a single route table. Each route table can be associated with zero to many attachments and can forward packets to other attachments.

Route propagation

Each attachment comes with routes that can be installed in one or more transit gateway route tables. When an attachment is propagated to a transit gateway route table, these routes are installed in the route table.

For a VPC attachment, the CIDR blocks of the VPC are propagated to the transit gateway route table.

When dynamic routing is used with a VPN attachment or a Direct Connect gateway attachment, you can propagate the routes learned from the on-premises router through BGP to any of the transit gateway route tables.

When dynamic routing is used with a VPC attachment, the routes in the route table associated with the VPN attachment are advertised to teh customer gateway through BGP.

For a connect attachment, routes in the route table associated with the Connect attachment are advertised to the third-party virtual appliances, such as SD-WAN appliances, running in a VPC through BGP.

For a Direct Connect gateway attachment, allowed prefix interactions control which routes are advertised to the customer network from AWS.

Whena static route and a propagated route have the same destination, the static route has the higher priority, so the propagated route is not included in the route table. If you remove the static route, the overlapping propagated route is included in the route table.

Routes for peering attachments

You can peer two transit gateways and route traffic between them. To do this, you create a peering attachment on your transit gateway and specify the peer transit gateway with which to create the peering connection. You then create a static route in your transit gateway route table to route traffic to the transit gatewya peering attachment. Traffic that's routed to the peer transit gateway can then be routed to the VPC and VPN attachements for the peer transit gateway.

For more information, see Example: Peered transit gateways.

Route evaluation order

Transit gateway routes are evaluated in the following order:

    The most specific route for the destination address.
    For routes with the same destination IP address but different targets, the route priority is as follows:
        Static routes (for example, Site-toSite VPN static routes)
        Prefix list referenced routes
        VPC propagated Routes
        Direct Connect gateway propagated routes
        Transit Gateway Connect propagated routes
        Site-to-Site VPN propagated routes

Transit gateway only  shows a preferred route. A backup route will only appear in the Transit Gateway route table if that route is no longer advertised. For example, if you are advertising the same routes over the Direct Connect gateway and over Site-to-Site VPN. AWS Transit Gateway will only show the routes received from the Direct Connect gateway route, which is the preferred route. The Site-to-Site VPN, which is the backup route, will only display when the Direct Connect gateway is no longer advertised.

Consider the following VPC route table. The VPC local route has the highest priority, followed by the routes that are more specific. When a static route and a propagated route have the same destination, the static route has a higher priority.

Destination | Target | Priority
10.0.0.0/16 | local | 1
192.168.0.0/16 | pcx-12345 | 2
172.31.0.0/16 | vgw-12345(static) or tgw-12345(static) | 2
172.31.0.0/16 | vgw-12345(propagated) | 3
0.0.0.0/0 | igw-12345 | 4

================================================================================================================
https://docs.aws.amazon.com/vpc/latest/tgw/tgw-getting-started.html

Getting started with transit gateways

The following tasks help you become familiar with transit gateways. You will create a transit gateway and then connect two of your VPCs using the transit gateway.

Tasks
    Prerequisites
    Step 1: Create the transit gateway
    Step 2: Attach your VPCs to your transit gateway
    Step 3: Add routes between the transit gateway and your VPCs
    Step 4: Test the transit gateway
    Step 5: Delete the transit gateway

Prerequisites

    To demonstrate a simple example of using a transit gateway, create two VPCs in the same Region. The VPCs cannot have overlapping CIDRs. Launch one Amazon EC2 instance in each VPC. For more information, see Get started with Amazon VPC in the Amazon VPC User Guide.

    You cannot have identical routes pointing to two different VPCs. A transit gateway does not propagate the CIDRs of a newly attached VPC if an identical route exists in the transit gateway route tables.

    Verify that you have the permissions required to work with transit gateways. For more information, see Authentication and access control for your transit gateways.

    You can't ping hosts if you haven't added an ICMP rule for each of the host security groups. For more information, see Work with security groups in the Amazon VPC User Guide.

Step 1: Create the transit gateway

When you create a transit gateway, we create a default transit gateway route table and use it as the default association route table and hte default propagation route table.

To create a transit gateway...

Create a transit gateway attachment to a VPC

    1. Open the Amazon VPC console at https://console.aws.amazon/vpc/
    2. On the naviation pane, choose Transit Gateway Attachments.
    3. Choose Create transit gateway attachment.
    4. (Optional) For Name tag, enter a name for the attachment.
    5. For Transit gateway ID, choose the transit gateway to use for the attachment.
    6. For attachment type, choose VPC.
    7. Choose whether to enable DNS support. For this exercise, do not enable IPv6 support.
    8. For VPC ID, choose the VPC to attach to the transit gateway.
    9. For Subnet IDs, select one subnet for each Availability Zone to be used by the transit gateway to route traffic. You must select at least one subnet. You can select only one subnet per Availability Zone.
    10. Choose Create transit gateway attachment.

Each attachment is always associated with exactly one route table. Route tables can be associated with zero to many attachments. To determine the routes to configure, decide on the use case for your transit gateway, and then configure the routese. For more information, see Examples.

Step 3: Add routes between the transit gateway and your VPCs

A route table includes dynamic and static routes that determine the next hop for associated VPCs based on the destination IP address of the packet. Configure a route that has a destination for non-local routes and the target of the transit gateway attachment ID. For more information, see Routing for a transit gateawy in Amazon VPC User Guide.

To add a route to a VPC route table

    1. Open the Amazon VPC console at https//console.aws.amazon.com/vpc/
    2. On the navigation pane, choose Route Tables.
    3. Choose the route table associated with your VPC.
    4. Choose the Routes tab, then choose Edit routes.
    5. Choose Add route.
    6. In the Destination column, enter the destination IP address range. For Target, choose Transit Gateway, and then choose the transit gateway ID.
    7. Choose Save changes.

...

https://docs.aws.amazon.com/vpc/latest/tgw/tgw-best-design-practices.html

Transit gateway design best practices

The following are best practices for your transit gateway design:

Use a separate subnet for each transit gateway VPC attachment. For each subnet, use a small CIDR, for example /28, so that you hae more addresses for EC2 resources. When you use a separate subnet, you can configure the following:
    Keep the inbound and outbound network ACLs associated with the transit gateway subnets open.
    Depending on your traffic flow, you can apply network ACLs to your workload subnets.

Create one network ACL and associate it with all of the subnets that are associated with the transit gateway. Keep the network ACL open in both the inbound and outbound directions.

Associate the same VPC route table with all of the subnets that are associated with the transit gateway, unless your network design requires multiple VPC route tables (for example, a middle-box VPC that routes traffic through multiple NAT gateways).

Use Border Gateway Protocol (BGP) Site-to-site VPN connections. If your customer gateway device or firewall for the connection supports multipath, enable the feature.

Enable route propagation for AWS Direct Connect gateway attachments and BGP Site-To-Site VPN attachments.

When migrating from VPC peering to use an AWS Transit Gateway,
    A transit gateway does not support Security Group referencing.
    An MTU size mismatch between VPC peering and transit gateway might result in some packets dropping for asymmetric traffic. Update both VPCs at the same time to avoid jumbo packets dropping due to size mismatch.

You do not need additional transit gateways for high availability, because transit gateways are highly available by design.

Limit the number of transit gateway route tables unless your design requires multiple transit gateway route tables.

For redundancy, use a single Transit Gateway in each Region for disaster recovery.

For deployments with multiple transit gateways, we recommend that you use a unique Autonomous System number (ASN) for each of your transit gateways. Transit Gateway also supports intra-Region peering. For more information, see Building a global network using AWS Transit Gateway Intra-Region peering.

https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html

Amazon CloudWatch concepts

The following terminology and concepts are central to your understanding and use of Amazon CloudWatch:

    Namespaces
    Metrics
    Dimensions
    Resolution
    Statistics
    Precentiles
    Alarms

Namespaces

A namespace is a container for CloudWatch metrics. Metrics in different namespaces are isolated from each other, so that metrics from different applications are not mistakenly aggreated into the same statistics.

There is no default namespace. You must specify a namespace for each data point you publish to CloudWatch. You can specify a namespace name when you create a metric. These names must contain valid XML characters and be fewer than 256 characters in length. Possible characters are: alphanumeric characters (0-9A-Za-z), period (.), hyphen(-), underscore(_), forward slash (/), hash (#), and colon (:).

The AWS namespaces typically use the following naming convention: AWS/service. For example, Amazon EC2 uses the AWS/EC2 namespace. For the list of AWS namespaces, see AWS services that publish CloudWatch metrics.

Metrics

Metrics are the fundamental concept in CloudWatch. A metric represents a time-ordered set of data points that are published to CloudWatch. Think of a metric as a variable to monitor, and the data points as representing the values of that variable over time. For example, the CPU usage of a particular EC2 instance is one metric provided by Amazon EC2. The data points themselves can come from any application or business activity from which you collect data.

By default, many AWS services provide free metrics for resources (such as Amazon EC2 instances, Amazon EBS volumnes, and Amazon RDS DB instances). For a charge, you can also enable detailed monitoring for some resources, such as your Amazon EC2 instances, or publish your own application metrics. For custom metrics, you can add the data points in any order, and at any rate you choose. Youc an retrieve statistics about those data points as an ordered set of time-series data.

Metrics exist onliy in the Region in which they are created. Metrics cannot be deleted, but they automatically expire after 15 months if no new data is published to them. Data points older than 15 months expire on a rolling basis; as new data points come in, data older than 15 months is dropped.

Metrics are uniquesly defined by a name, namespace, and zero or more dimensions. Each data point in a metric has a time stamp, and (optionally) a unit of measure. You can retrieve statistics from CloudWatch for any metric.

For more information, see Viewing available metrics and Publishing Custom metrics.

Time stamps

Each metric data point must be associated with a time stamp. The time stamp can be up to two weeks in the past and up to two hours into the future. If you do not provide a time stamp, CloudWatch creates a times tamp for you based on the time the data point was received.

Time stamps are dateTime objects, with the complete date plus hours, minutes, and seconds (for example, 2016-10-31T23:59:59Z). For more information, see dateTime. Although it is not required, we recommend that you use Coordinated Universal Time (UTC). When you retrieve statistics from CloudWatch, all times are in UTC.

CloudWatch alarms check metrics based on the current time in UTC. Custom metrics sent to CloudWatch with time stamps other than the current UTC time can cause alarms to display the Insufficient Data state or result in delayed alarms.

=====================================================================================================================
https://academy.uipath.com/learningpath-viewer/6053/1/250085/3

Introduction to Version Control Systems

What are version control systems?

Version control systems are tools used by software development teams to manage the collaboration on large projects.

A version control system allows developers to track a code change, review the history of the code, and revert to a previous version of the project if needed.

Here are some benefits of using version control systems:

Enhanced Collaboration: Team members can work freely on any file at any time and merge the changes into a common version at the right time.

Storing versions: Only the current version is stored on the disk; all others are in the system.

Restoring previous versions: Restore older versions of the file at any time.

Tracking different project versions: New versions are usually saved with change discriptions. Versions of the same file can also be compared.

The verson control systems UiPath Studio is integrated with are Git, TFS, and SVN. The connection to a version control system is done at the project level. To manage your connections, access Studio, go to the Backstage view, and click the team tab.

Alternatively, the Add to Source Control button in the status bar offers shortcuts to Git Init, Copy to Git, Add to TFS, and Add to SVN.

Note: You cannot connect a project to GIT, TFS, and SVN at the same time.

Which version control system should you choose?

Regardless of the type o version control system used, project files are stored on a s erver where you push your files after you have completed your work on your local machine.

However, deciding whether to use a centralized version control system like SVN or a distributed version control system like Git affectshow you commit changes. This will be covered later in the course.

A Closer Look at Git

Git Overview

Git is an open-source version control system. Git is distributed, unlike older centralized verson control systems such as SVN and CVS, which allows every developer to have a complete histo9ry of their code repository locally. This makes the intial clone of the repository slower, but subsequent operations such as commit, blame, diff, merge, and log dramatically faster.

Git also has good support for branching, merging, and rewriting repository history. The pull request is one popular feature that allows teams to collaborate on Git branches and efficiently review each other's code. Git is the most widely used version control system in the world and is considered the modern standard in software development.

Here is a basic overview of how Git works:

    1. Create a repository (project) with a Git hosting tool
    2. Copy or clone the repository to your local machine.
    3. Add a file to your local repository and commit (save) the changes locally.
    4. Push you changes to the remote repository.
    5. Another developer in the team can pull the file to their local repository and make changes, then they can commit and push the file.
    6. They can also create a branch (alternative), make a change, commit the change.
    7. On a pull request (propose chagnes to the master branch).
    8. Merge your branch to the master branch.

SVN and Git side-by-side

With a centralized system, the SVN version control system stores all files and historical data on a central server. The developers commit their changes to this central server repository.

Trunk: The trunk is the hub of yoru current, stable code and product. It only includes tested, unbroken code.

Branches: Here you add the new codes and features. Using a copy of the trunk code, team members conduct research and development in the branch. This allows each team member to work on the enhanced features without disrupting each other's progress.

Tags: Tags are a duplicate of a branch at a given point in time. Tags are not used during development but are used during deployment after the branch's code is completed. Marking code with tags makes it easy to review, and, if necessary, revert your code.

==============================================================================
https://docs.aws.amazon.com/directoryservice/latest/admin-guide/directory_ad_connector.html

Active Directory Connector

AD Connector is a directory gateway with which you can redirect directory requests to your on-premises Microsoft Active Directory without caching any information in the cloud. AD Connector comes in two sizes, small and large. You can spread application loads across multiple AD connectors to scale to your performance needs. There are no enforced user or connection limits.

AD Connector does not support AD transitive trusts. AD Connectors and your on-premises AD domains have a 1-to-1 relationship. That is, for each on-premises domain, including child domains in an AD forest that you want ot authenticate against, you must create a unique AD connector.

Note AD Connector cannot be shared with other AWS accounts. If this is a requirement, consider using AWS Managed Microsoft AD to Share your directory. AD Connector is also not multi-VPC aware, which means that AWS applications like WorkSpaces are required to be provisioned in the same VPC as your AD Connector.

Once set up, AD Connector offers the following benefits:

    Your end users and IT administrators can use thier existing corporate credentials to log on to AWS applications such as WorkSpaces, Amazon WorkDocs, and Amazon WorkMail.

    You can manage AWS resources like Amazon EC2 instances or Amazon S3 buckets through IAM role-based access to the AWS Management Console.

    You can consistently enforce existing security policies (such as password expiration, password history, and account lockouts) whether users or IT administrators are accessing resources in your on-premises infrastructure in the AWS Cloud.

    You can use AD Connector to enable multi-factor authentication by integrating with your existing RADIUS-based MFA infrastructure to provide an additional layer of security when users access AWS applications.

Continue reading the topics in this secion to learn how to connect a directory and make the most of AD Connector features.

====================================================================================
https://docs.aws.amazon.com/directoryservice/latest/admin-guide/prereq_connector.html

AD Connector prerequisites

To connect your existing directory with an AD connector, you need the following:

VPC

Set up a VPC with the following:

    At least two subnets. Each of the subnets must be in a different Availability Zone.
    The VPC must be connected to your existing network through a virtual private network (VPN) connection or AWS Direct Connect.
    The VPC must have default hardware tenancy.

AWS Directory Services uses a two VPC structure. The EC2 instances which make up your dierctory run outside of your AWS account, and are managed by AWS. They ahve two network adapters, ETH0 and ETH1. ETH0 is the management adapter, and exists outside of your network. ETH1 is created within your account.

The management IP range of your directory's ETH0 netowrk is chosen programmatically to ensure it does not conflict with the VPC where you directory is deployed. This IP range can be in either of the following pairs (as Directories run in two subnets):

    10.0.1.0/24 & 10.0.2.0.24
    192.168.1.0/24 & 192.168.2.0/24

We avoid conflicts by checking the first octet of the the ETH1 CIDR. If it starts with a 10, then we choose a 192.168.0.0/16 VPC with 192.168.1.0/24 and 192.168.2.0/24 subnets. If the first octet is anything else other than a 10, we choose a 10.0.0.0/16 VPC with 10.0.1.0/24 and 10.0.2.0/24 subnets.

The selection algorithm does not include routes on your VPC. It is therefore possible to have an IP routing conflict result from this scenario.

The VPC must NOT be configured with the following VPC endpoint(s):

    Route 53 VPC endpoints that include DNS conditional overrides for *.amazonaws.com which resolve to non public AWS IP addresses
    CloudWatch VPC endpoint
    Systsms Manager VPC endpoint
    Security Token Service VPC endpoint

For more information, see the following topics in Amazon VPC User Guide:

===============================================================================
https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-guide.html

Working with AWS CloudFormation templates

To provision and configure your stack resources, you must understand AWS CloudFormation templates, which are formatted text files in JSON or YAML. These templates describe the resources that you want to provision in your AWS CloudFormation stacks. You can use AWS CloudFormation Designer or any text editor to create and save templates. For more information about the structure and syntax of a template, see Template anatomy.

If you're unfamiliar with JSON or YAML, you can use AWS CloudFormation Designer to help you get started with AWS CloudFormation templates. AWS CloudFormation Designer is a tool for visually creating and modifying templates. For more information, see What is AWS CloudFormation Designer?.

Template snippets provides examples that demonstrate how to write templates for a particular resource. For example, you can view snippets for Amazon EC2 instances, Amazon S3 domains, AWS CloudFormation mappings, and more. Snippets are grouped by resource, wiht general purpose AWS CloudFormation snippets in General template snippets.

For details about the supported resources, type names, intrinsic functions, and pseudo parameters you can use in your templates, see Template reference.

Topics
  AWS CloudFormation template formats
  Template anatomy
  What is AWS CloudFormation Designer?
  Walkthroughs
  Template snippets
  Custom resources
  Using AWS CloudFormation macros to perform custom processing on templates
  Using modules to encapsulate and reuse resource configurations
  Perform ECS blue/green deployments through CodeDeploy using AWS CloudFormation
  Using regular expressions in AWS CloudFormation templates

AWS CloudFormation template formats

You can authos AWS CloudFormation templates in JSON or YAML formats. We support all AWS CloudFormation features for both formats, including AWS CloudFormation Designer.

When deciding which format to use, pick the format you're most comfortable working in. Also consider that YAML inherently provides some features, such as commenting, that aren't available in JSON.

Important: We recommend that you don't add # YAML comments to your templates in Designer. If your YAML templates have # comments, Designer doesn't preserve those comments when converting the template to JSON. In addition, if you modify your template in Designer (for example, if you move a resources on the canvas), your comments are lost.

You can add comments to the AWS CloudFormation templates you create outside of Designer. The following example shows a YAML template with inline comments.

AWSTemplateFormatVersion: "2010-09-09"
Description: A Sample template
Resources:
  MyEC2Instance: #An inline comment
    Type: "AWS::EC2::Instance"
    Properties:
      ImageID: "ami-0ff8a91507f77f867" #Another comment -- This is a Linux AMI
      InstanceType: t2.micro
      KeyName: testkey
      BlockDeviceMappings:
        -
          DeviceName: /dev/sdm
          Ebs:
            VolumeType: io1
            Iops:200
            DeleteOnTermination: false
            VolumeSize: 20

For more information about the template syntax for each format, see Template anatomy.

AWS CloudFormation supports the following JSON and YAML specifications:

JSON
  AWS CloudFormation follows the ECMA-404 JSON standard. For more information about the JSON format, see http://www.json.org.

YAML
  AWS CloudFormation supports the YAML Version 1.1 sepcification with a few exceptions.
  AWS CloudFormation doesn't support the following features:
    The binary, omap, pair, set, and timestamp tags
    Aliases
    Hash merges
  For more information about YAML, see https://yaml.org.

Template anatomy

A template is a JSON- or YAML-formatted text file that describes your AWS infrastrcture.

JSON
The following example shows a JSON-formatted template fragmetn.
{
  "AWSTemplateFormatVersion" : "version date",

  "Description" : "JSON string",

  "Metadata" : {
    template metadata
  }

  "Parameters" : {
    set of parameters
  },

  "Mappings" : {
    set of mappings
  },

  "Conditions" : {
    set of conditions
  },

  "Transform" : {
    set of transforms
  }

  "Resources" : {
    set of resources
  },

  "Outputs" : {
    set of outputs
  }
}

Template sections

Templates include several major sections. The Resources section is hte only required section. Some sections in a template can be in any order. However, as you build your template, it can be helpful to use the logical order shown in the following list because values in one section might refer to values from a previous section.

Format version (optional)
  The AWS CloudFormation template version that the template conforms to. The template format version isn't hte same as the API or VSDL version. The template format version can change independently of the API and WSDL versions.

Description (optional)
  A text string that describes the template. This seciotn must always follow the templat format version section.

Metadata (optional)
  Objects that provide additional information about the template

...


Format version

The AWSTemplateFormatVersion section (optional) identifies the capabilities of the template. The latest formate version is 2010-09-09 and is currently the only valid value.

Note:
The tempalte format version isn't the same as the API or WSDL version. The template format version can change independendtly of the API asnd WSDDL versions.

The value for the template format version declaration must be a literal string. You can't use a parameter or function to specify the template format version. If you don't specify a value, AWS Cloudformation assumes the latest format version. The following snippet is an example of a valid template format version declaration:

JSON
"AWSTemplateFormatVersion": "2010-09-09"

====================================================================================

Metadata

You can use the optional Metadata section to include arbitrary JSON or YAML objects that provide details about the template. For example, you can include template implementation details about specific resources, as shown in the following snippet:

Important
During a stack update, you cannot update the metadata section by itself. You can update it only when you include changes that add, modify, or delete resources.

Important
CloudFormation does not transform, modify, or redact any information you include in the Metadata section. Because of this, we strongly recommend you do not use this section to store sensitive information, such as passwords or secrets.

JSON
"Metadata" : {
  "Instances" : {"Description" : "Information about the instances"},
  "Databases" : {"Description" : "Information about databases"}
}

Metadata keys

Some AWS CloudFormation features retrieve settings or configuration information that youd efine in the Metadata section. You define this information in the following AWS CloudFormation-specific metadata keys:

AWS::CloudFormation::Init
  Defines configuration tasks for the cfn-init helper script. This script is useful for configuring and installing applications on EC2 instances. For more information, see AWS::CloudFormation::Init.

AWS::CloudFormation::Interface
  Defines the grouping and ordering of input parameters when they are displayed in the AWS CloudFormation console. By default, the AWS CloudFormation console aplphabetically sorts parameters by their logical ID. For more information, see AWS::CloudFormation::Interface.

AWS::CloudFormation::Designer
  Describes how your resources are laid out in AWS CloudFormation Designer (Designer). Designer automatically adds this information when you use it to create an update templates. For more information, see What is AWS CloudFomration Designer?

https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-authentication.html

AWS::CloudFormation::Authentication

Use the AWS::CloudFormation::Authentication resource to specify authentication credentials for files or sources that you specify with the AWS::CloudFormation::Init resource.

To include authentication information for a file or source that you specify with AWS::CloudFormation::init, use the uris property if the source is a URI or the buckets propertiy if the source is an Amazon S3 bucket. For more information about files, see Files. For more information about sources, see Sources.

You can also specify authentication information for files directly in the AWS::CloudFormation::Init resource. The files key of the resource contains a property named authentication. You can use the authentication property to associate authentication information defined in an AWS::CloudFormation::Authentication resource directly with a file.

For files, AWS CloudFormation looks for authentication information in the following order:
  1. The authentication property of the AWS::CloudFormation::Init files key.
  2. The uris or buckets property of the AWS::CloudFormation::Authentication resource.

For sources, CloudFormation looks for authentication information in the uris or buckets property of the AWS::CloudFormation::Authentication resource.

Topics
  Syntax
  Properties
  Examples

Syntax

To declare this entity in your CloudFormation tempalte, use the following syntax:

You should be aware of the following considerations whne using the AWS::CloudFormation::Authenticaiton type:

  Unlike CloudFormation resources, the AWS::CloudFormation::Authentication type doesn't contain a block called properties, but instead contians a list of user-named blocks, even containing its own authentication properties. Not all properties pertain to each authenticaiton type; see the type property for more details.

  Unlike most CloudFormation resources, property names use lower camel case.

JSON
{
  "Type" : "AWS::CloudFormation::Authentication" {
    "String" : {
      "accessKeyId": String,
      "buckets" : [String, ...],
      "password" : String,
      "secretKey" : String,
      "type" : String,
      "uris" : [ String, ... ],
      "username" : String,
      "roleName" : String
    }
  }
}

Properties

accessKeyId
  Specifies the access key ID for S3 authenticaiton.
  Required: Conditional. Can be specified only if the type property is set to "S3".
  Type: String

buckets
  A comma-delimited list of Amazon S3 buckets to be associated with the S3 authenticaiton credentials.
  Required: Conditional. Can be specified only if the type property is set to "S3".
  Type: List of String values

password
  Specifies the password for basic authentication.
  Required: Conditional. Can be specified only if the type property is set to "basic".
  Type: String




















































































end of copii
What version of SQL Server are we currently running?
What does it mean to crawl data sources to discover schema?
what is an ODBC DSN configuration?
